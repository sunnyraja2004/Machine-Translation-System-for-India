{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6XxjkuwX_iZv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XxjkuwX_iZv"
      },
      "source": [
        "# Text Processing For English"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP1GkUfHG-ao"
      },
      "source": [
        "## Prerequisites: Install [SpaCy](https://spacy.io/)\n",
        "**spaCy** is a relatively new framework in the Python Natural Language Processing environment. There are some really good reasons for its popularity:\n",
        "\n",
        "\n",
        "*   **It's really FAST**\n",
        "  * Written in Cython, it was specifically designed to be as fast as possible\n",
        "\n",
        "*   **It's really ACCURATE**\n",
        "  * spaCy implementation of its dependency parser is one of the best-performing in the world:\n",
        " [ It Depends: Dependency Parser Comparison\n",
        "Using A Web-based Evaluation Tool](https://aclweb.org/anthology/P/P15/P15-1038.pdf)\n",
        "\n",
        "* **Batteries included**\n",
        "  * *Index preserving tokenization*\n",
        "  * Models for *Part Of Speech tagging, Named Entity Recognition* and *Dependency Parsing*\n",
        "  * Supports *8 languages* out of the box\n",
        "  * Easy and *beautiful visualizations*\n",
        "  * Pretrained *word vectors*\n",
        "# New section\n",
        "* **Extensible**\n",
        "  * It plays nicely with all the other already existing tools that are popular: Scikit-Learn, TensorFlow, gensim\n",
        "\n",
        "* **DeepLearning Ready**\n",
        "  * It also has its own deep learning framework that’s especially designed for NLP tasks: [Thinc: A refreshing functional take on deep learning, compatible with your favorite libraries](https://github.com/explosion/thinc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fucBLMFLGzhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785ff269-a3bf-449a-8ca7-6229b44c5307"
      },
      "source": [
        "!python3 -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei0pZ-4D5gZe"
      },
      "source": [
        "`Notice that the installation doesn’t automatically download the English model. We need to do that ourselves. This pipeline for English data, later in this tutorial we will do text processing for hindi dataset.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtRR7wBYHFuz"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30FSoy9BHTs5"
      },
      "source": [
        "## Tokenization and Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU6E07Yw5zvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2adafa51-cbaf-45a8-921b-48681e27c9b4"
      },
      "source": [
        "# Token Text\n",
        "\n",
        "doc = nlp('Hello     World!')\n",
        "print(\"doc contains the string is:\", doc)\n",
        "\n",
        "# Iterate over tokens in a Doc\n",
        "for token in doc:\n",
        "    print('\"' + token.text + '\"')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "doc contains the string is: Hello     World!\n",
            "\"Hello\"\n",
            "\"    \"\n",
            "\"World\"\n",
            "\"!\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsmcBvYP5tXP"
      },
      "source": [
        "Notice the index preserving tokenization in action. Rather than only keeping the words, spaCy keeps the spaces too. This is helpful for situations when you need to replace words in the original text or add some annotations. With NLTK tokenization, there’s no way to know exactly where a tokenized word is in the original raw text. spaCy preserves this “link” between the word and its place in the raw text. Here’s how to get the exact index of a word:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuBV1HeZ8o1w"
      },
      "source": [
        "The `Token` class exposes a lot of word-level attributes. Here are a few examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL3ScmXV85l0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb00b3b-69f6-4725-c120-4a9f94d897df"
      },
      "source": [
        "doc = nlp(\"Next week I'll   be in India.\")\n",
        "print(\"text\",\"\\tid\",\"\\tlemma\",\"\\tpunct?\",\"\\tspace?\",\"\\tshape\",\"\\tpos\",\"\\ttag\",\"\\tdep\")\n",
        "print(\"--------------------------------------------------------------------------\")\n",
        "for token in doc:\n",
        "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
        "        token.text,\n",
        "        token.idx,\n",
        "        token.lemma_,\n",
        "        token.is_punct,\n",
        "        token.is_space,\n",
        "        token.shape_,\n",
        "        token.pos_,\n",
        "        token.tag_\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text \tid \tlemma \tpunct? \tspace? \tshape \tpos \ttag \tdep\n",
            "--------------------------------------------------------------------------\n",
            "Next\t0\tnext\tFalse\tFalse\tXxxx\tADJ\tJJ\n",
            "week\t5\tweek\tFalse\tFalse\txxxx\tNOUN\tNN\n",
            "I\t10\tI\tFalse\tFalse\tX\tPRON\tPRP\n",
            "'ll\t11\twill\tFalse\tFalse\t'xx\tAUX\tMD\n",
            "  \t15\t  \tFalse\tTrue\t  \tSPACE\t_SP\n",
            "be\t17\tbe\tFalse\tFalse\txx\tAUX\tVB\n",
            "in\t20\tin\tFalse\tFalse\txx\tADP\tIN\n",
            "India\t23\tIndia\tFalse\tFalse\tXxxxx\tPROPN\tNNP\n",
            ".\t28\t.\tTrue\tFalse\t.\tPUNCT\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FVzvUsF6Gel"
      },
      "source": [
        "sentence = u\"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
        "\n",
        "#TODO: Print the tokens and all word level attributes of the sentences."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg4SPjUd-pST"
      },
      "source": [
        "### Sentence detection\n",
        "Here’s how to achieve one of the most common NLP tasks with spaCy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA8br2bz-zZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5746e4-c9ee-455d-aa72-6d44f8243810"
      },
      "source": [
        "doc = nlp(\"These are apples. These are oranges.\")\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "These are apples.\n",
            "These are oranges.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEWLckY3XfIA"
      },
      "source": [
        "# Sentence Detection\n",
        "\n",
        "doc = nlp(u\"Natural language (NL) refers to the language spoken/written by humans. NL is the primary mode of communication for humans. With the growth of the world wide web, data in the form of text has grown exponentially. It calls for the development of algorithms and techniques for processing natural language for the automation and development of intelligent machines.\")\n",
        "\n",
        "#TODO: Print all the valid sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIlUVKHm_XIy"
      },
      "source": [
        "## Part Of Speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAK3W215_bM6"
      },
      "source": [
        "doc = nlp(\"Next week I'll be in Madrid.\")\n",
        "print([(token.text, token.tag_) for token in doc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBj5bVwqHm9t"
      },
      "source": [
        "# POS Tagging\n",
        "\n",
        "sentence = u\"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value.\"\n",
        "\n",
        "#TODO: Print the POS of each token."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV8FgfGFAUck"
      },
      "source": [
        "## Named Entity Recognition\n",
        "Doing NER with spaCy is super easy and the pretrained model performs pretty well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf6cD4IpAlB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad589db8-208d-439b-85f4-a6549481adf1"
      },
      "source": [
        "doc = nlp(\"Next week I'll be in Madrid.\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next week DATE\n",
            "Madrid GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxdAMOi2COGV"
      },
      "source": [
        "### Spacy Entity Types\n",
        "The spaCy NER also has a healthy variety of entities. You can view the full list here: [Entity Types](https://spacy.io/usage/linguistic-features#entity-types)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXG_lWC4CV7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b856c9-c641-4a36-fcea-5f335bd4ac54"
      },
      "source": [
        "doc = nlp(u\"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 CARDINAL\n",
            "9 a.m. TIME\n",
            "30% PERCENT\n",
            "just 2 days DATE\n",
            "WSJ ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jMsSARKCnWG"
      },
      "source": [
        "Entity text and its label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TObVZI9BCpVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "271f172c-09cb-4bd8-93b9-860482682d5d"
      },
      "source": [
        "# Iterate over the doc.ents and print the entity text and label_ attribute.\n",
        "\n",
        "text = \"I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\"\n",
        "\n",
        "# Process the text\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate over the predicted entities\n",
        "for ent in doc.ents:\n",
        "    # Print the entity text and its label\n",
        "    print(f\"{ent.text:<15}{ent.label_:<12}{spacy.explain(ent.label_):<12}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2              CARDINAL    Numerals that do not fall under another type\n",
            "9 a.m.         TIME        Times smaller than a day\n",
            "30%            PERCENT     Percentage, including \"%\"\n",
            "just 2 days    DATE        Absolute or relative dates or periods\n",
            "WSJ            ORG         Companies, agencies, institutions, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iii-49GxBJ8f"
      },
      "source": [
        "You can also view the Inside–outside–beginning (IOB) style tagging of the sentence like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIi5sSEaBPnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0236aa-d22d-4881-9215-8de00bc63646"
      },
      "source": [
        "from nltk.chunk import conlltags2tree\n",
        "\n",
        "\n",
        "doc = nlp(\"Next week I'll be in Madrid.\")\n",
        "iob_tagged = [\n",
        "    (\n",
        "        token.text,\n",
        "        token.tag_,\n",
        "        \"{0}-{1}\".format(token.ent_iob_, token.ent_type_) if token.ent_iob_ != 'O' else token.ent_iob_\n",
        "    ) for token in doc\n",
        "]\n",
        "\n",
        "print(iob_tagged)\n",
        "\n",
        "# In case you like the nltk.Tree format\n",
        "print(conlltags2tree(iob_tagged))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Next', 'JJ', 'B-DATE'), ('week', 'NN', 'I-DATE'), ('I', 'PRP', 'O'), (\"'ll\", 'MD', 'O'), ('be', 'VB', 'O'), ('in', 'IN', 'O'), ('Madrid', 'NNP', 'B-GPE'), ('.', '.', 'O')]\n",
            "(S\n",
            "  (DATE Next/JJ week/NN)\n",
            "  I/PRP\n",
            "  'll/MD\n",
            "  be/VB\n",
            "  in/IN\n",
            "  (GPE Madrid/NNP)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOUY7WoAHqU2"
      },
      "source": [
        "# NER Named Entity Recognition\n",
        "\n",
        "sentence = u\"A UN review of national plans to cut carbon says they are well short of the levels needed to keep the rise in global temperatures under 2C. Many scientists say that technology to remove carbon from the air will now be needed to meet the Paris targets.\"\n",
        "\n",
        "#TODO: Print the entities along with their labels that are found in the sentence."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6gboJIdV7fU"
      },
      "source": [
        "# Print the entity text, label attribute and explains the lables for each entity.\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value. I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DejoSbvqDBi7"
      },
      "source": [
        "# Print the entity text, label attribute in the IOB style tagging.\n",
        "\n",
        "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value. I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt3ciVtpEjtF"
      },
      "source": [
        "Let’s use `displaCy` to view a beautiful visualization of the Named Entity annotated sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyvSmbsGEyv9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "86e7aaa3-c148-4e4b-8690-38ebab2bae7f"
      },
      "source": [
        "# displaCy\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(u'I just bought 2 shares at 9 a.m. because the stock went up 30% in just 2 days according to the WSJ')\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I just bought \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " shares at \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    9 a.m.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              " because the stock went up \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    30%\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    just 2 days\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " according to the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    WSJ\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80yDB2vdFH8n"
      },
      "source": [
        "# displaCy\n",
        "\n",
        "sentence = u\"A UN review of national plans to cut carbon says they are well short of the levels needed to keep the rise in global temperatures under 2C. Many scientists say that technology to remove carbon from the air will now be needed to meet the Paris targets.\"\n",
        "\n",
        "#TODO: Visualize the Named Entity annotated sentence using displayCy."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gznf3CS4GEti"
      },
      "source": [
        "### Chunking\n",
        "spaCy automatically detects noun-phrases as well:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m-w-ZdHGENH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e03de7-d496-4e41-e1db-1ed8d90bd633"
      },
      "source": [
        "# Chunking\n",
        "doc = nlp(\"Wall Street Journal just published an interesting piece on crypto currencies\")\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text, chunk.label_, chunk.root.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall Street Journal NP Journal\n",
            "an interesting piece NP piece\n",
            "crypto currencies NP currencies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K4puxx-GPgj"
      },
      "source": [
        "Notice how the chunker also computes the root of the phrase, the main word of the phrase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSN8Jwi3L-nA"
      },
      "source": [
        "## Dependency Parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3OIxXy9GbnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60936538-3a9b-4981-d091-788f5da3a4a3"
      },
      "source": [
        "# Dependency Parsing\n",
        "\n",
        "doc = nlp(u'Wall Street Journal just published an interesting piece on crypto currencies')\n",
        "\n",
        "for token in doc:\n",
        "    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n",
        "        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall/NNP <--compound-- Street/NNP\n",
            "Street/NNP <--compound-- Journal/NNP\n",
            "Journal/NNP <--nsubj-- published/VBD\n",
            "just/RB <--advmod-- published/VBD\n",
            "published/VBD <--ROOT-- published/VBD\n",
            "an/DT <--det-- piece/NN\n",
            "interesting/JJ <--amod-- piece/NN\n",
            "piece/NN <--dobj-- published/VBD\n",
            "on/IN <--prep-- piece/NN\n",
            "crypto/JJ <--amod-- currencies/NNS\n",
            "currencies/NNS <--pobj-- on/IN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRDvxTriGly_"
      },
      "source": [
        "If this doesn’t help visualizing the dependency tree, displaCy comes in handy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LrjMNkUGphD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "4bedd774-a6cc-4fb5-99a3-a9c6cc4e1d60"
      },
      "source": [
        "# Visualizing Dependency Parsing\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(u'Wall Street Journal just published an interesting piece on crypto currencies')\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})\n",
        "for token in doc:\n",
        "    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n",
        "        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"b89fd3fb160345108a9f6dcb561514a2-0\" class=\"displacy\" width=\"1040\" height=\"272.0\" direction=\"ltr\" style=\"max-width: none; height: 272.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Wall</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">Street</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">Journal</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">just</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">published</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">an</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">interesting</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">piece</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">on</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">crypto</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"182.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">currencies</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-0\" stroke-width=\"2px\" d=\"M70,137.0 C70,92.0 130.0,92.0 130.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,139.0 L62,127.0 78,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-1\" stroke-width=\"2px\" d=\"M160,137.0 C160,92.0 220.0,92.0 220.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,139.0 L152,127.0 168,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-2\" stroke-width=\"2px\" d=\"M250,137.0 C250,47.0 405.0,47.0 405.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M250,139.0 L242,127.0 258,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-3\" stroke-width=\"2px\" d=\"M340,137.0 C340,92.0 400.0,92.0 400.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340,139.0 L332,127.0 348,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-4\" stroke-width=\"2px\" d=\"M520,137.0 C520,47.0 675.0,47.0 675.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M520,139.0 L512,127.0 528,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-5\" stroke-width=\"2px\" d=\"M610,137.0 C610,92.0 670.0,92.0 670.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M610,139.0 L602,127.0 618,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-6\" stroke-width=\"2px\" d=\"M430,137.0 C430,2.0 680.0,2.0 680.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M680.0,139.0 L688.0,127.0 672.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-7\" stroke-width=\"2px\" d=\"M700,137.0 C700,92.0 760.0,92.0 760.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M760.0,139.0 L768.0,127.0 752.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-8\" stroke-width=\"2px\" d=\"M880,137.0 C880,92.0 940.0,92.0 940.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M880,139.0 L872,127.0 888,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-b89fd3fb160345108a9f6dcb561514a2-0-9\" stroke-width=\"2px\" d=\"M790,137.0 C790,47.0 945.0,47.0 945.0,137.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-b89fd3fb160345108a9f6dcb561514a2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945.0,139.0 L953.0,127.0 937.0,127.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wall/NNP <--compound-- Street/NNP\n",
            "Street/NNP <--compound-- Journal/NNP\n",
            "Journal/NNP <--nsubj-- published/VBD\n",
            "just/RB <--advmod-- published/VBD\n",
            "published/VBD <--ROOT-- published/VBD\n",
            "an/DT <--det-- piece/NN\n",
            "interesting/JJ <--amod-- piece/NN\n",
            "piece/NN <--dobj-- published/VBD\n",
            "on/IN <--prep-- piece/NN\n",
            "crypto/JJ <--amod-- currencies/NNS\n",
            "currencies/NNS <--pobj-- on/IN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpGst2DYG_xn"
      },
      "source": [
        "sentence = u'It took me more than two hours to translate a few pages of English.'\n",
        "\n",
        "#TODO:  Detect all Noun-phrases in the sentence."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPATaPcOHRkj"
      },
      "source": [
        "sentence = u'It took me more than two hours to translate a few pages of English.'\n",
        "\n",
        "#TODO:  Print Dependency Parsing."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_f8RA2lHtpb"
      },
      "source": [
        "sentence = u'It took me more than two hours to translate a few pages of English.'\n",
        "\n",
        "#TODO:  Visualizing Dependency Parsing.\n",
        "\n",
        "#You can also try:\n",
        "  # 1. Print the headwords and their dependencies\n",
        "  # 2. Print the Head/Root of a sentence\n",
        "  # 3. Print the ancestor of Translate\n",
        "  # 4. Print the childrens of piece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHyeV7HBrhY0"
      },
      "source": [
        "# Text Processing For Hindi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSdV5n-Onr45"
      },
      "source": [
        "Currently trained pipeline is not available in Spacy. So we are going to use [Indic NLP Library](https://anoopkunchukuttan.github.io/indic_nlp_library/) Resources and tools for Indian language Natural Language Processing.\n",
        "\n",
        "The goal of the Indic NLP Library is to build Python based libraries for common text processing and Natural Language Processing in Indian languages. Indian languages share a lot of similarity in terms of script, phonology, language syntax, etc. and this library is an attempt to provide a general solution to very commonly required toolsets for Indian language text. But in this tutorial our main focus will be on Hindi only.\n",
        "\n",
        "The library provides the following functionalities:\n",
        "\n",
        "* Text Normalization\n",
        "* Script Information\n",
        "* Tokenization\n",
        "* Word Segmentation\n",
        "* Script Conversion\n",
        "* Romanization\n",
        "* Indicization\n",
        "* Transliteration\n",
        "\n",
        "## Pre-requisites\n",
        "\n",
        "- Python 3.5+\n",
        "- [Morfessor 2.0 Python Library](http://www.cis.hut.fi/projects/morpho/morfessor2.shtml)\n",
        "\n",
        "## Language Support\n",
        "* Indo-Aryan\n",
        "  * Assamese -- asm\n",
        "  * Bengali -- ben\n",
        "  * Gujrati -- guj\n",
        "  * Hindi -- hin\n",
        "  * Urdu  -- urd\n",
        "  * Marathi -- mar\n",
        "  * Nepali -- nep\n",
        "  * Odia -- ori\n",
        "  * Punjabi -- pan\n",
        "  * Sindhi -- sin\n",
        "  * Sanskrit -- san\n",
        "  * Konkani -- kok\n",
        "\n",
        "* Dravidian\n",
        "  * Kannada -- kan\n",
        "  * Malayalam -- mal\n",
        "  * Telgu -- tel\n",
        "  * Tamil -- tam\n",
        "\n",
        "* Others\n",
        "  * English -- eng\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EvlMxSuv3SX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbdc02c-2944-4ec1-eb98-d026b772700f"
      },
      "source": [
        "!git clone \"https://github.com/anoopkunchukuttan/indic_nlp_library\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_library'...\n",
            "remote: Enumerating objects: 1404, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 1404 (delta 139), reused 152 (delta 124), pack-reused 1219 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1404/1404), 9.57 MiB | 11.55 MiB/s, done.\n",
            "Resolving deltas: 100% (749/749), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx_QnQS9rfBx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96342259-c16b-4ed8-dc61-249383c32cb0"
      },
      "source": [
        "!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'indic_nlp_resources'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 139 (delta 2), reused 2 (delta 0), pack-reused 126 (from 1)\u001b[K\n",
            "Receiving objects: 100% (139/139), 149.77 MiB | 32.75 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Updating files: 100% (28/28), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgwL0Oqdtbjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2400fca-49f8-4a08-a337-f727b126b172"
      },
      "source": [
        "!pip install Morfessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qce8rsdN3EFZ"
      },
      "source": [
        "**----- Set these variables -----**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiVGPkVzuSeo"
      },
      "source": [
        "# The path to the local git repo for Indic NLP library\n",
        "INDIC_NLP_LIB_HOME=r\"/content/indic_nlp_library\"\n",
        "\n",
        "# The path to the local git repo for Indic NLP Resources\n",
        "INDIC_NLP_RESOURCES=\"/content/indic_nlp_resources\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax9MkY0o3KWe"
      },
      "source": [
        "**Add Library to Python path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Ab0H820eDs"
      },
      "source": [
        "import sys\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC1oET6P3aJd"
      },
      "source": [
        "**Set environment variable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4TjmcYovLat"
      },
      "source": [
        "from indicnlp import common\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9wpTRM53g1p"
      },
      "source": [
        "**Initialize the Indic NLP library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUbL6hCpvbVn"
      },
      "source": [
        "from indicnlp import loader\n",
        "loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc26OSE1hSlp"
      },
      "source": [
        "## Text Normalization\n",
        "\n",
        "Text written in Indic scripts display a lot of quirky behaviour on account of varying input methods, multiple representations for the same character, etc.\n",
        "There is a need to canonicalize the representation of text so that NLP applications can handle the data in a consistent manner. The canonicalization primarily handles the following issues:\n",
        "\n",
        "    - Non-spacing characters like ZWJ/ZWNL\n",
        "    - Multiple representations of Nukta based characters\n",
        "    - Multiple representations of two part dependent vowel signs\n",
        "    - Typing inconsistencies: e.g. use of pipe (|) for poorna virama\n",
        "\n",
        "When data available is scarce, such normalization can help utilize the data more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VHrUO_Khhbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f421645-d843-4975-e922-8bd5d793f6ac"
      },
      "source": [
        "# from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "from indicnlp.normalize.indic_normalize import BaseNormalizer\n",
        "\n",
        "input_text=\"\\u0958 \\u0915\\u093c\"\n",
        "remove_nuktas=False\n",
        "# factory=IndicNormalizerFactory()\n",
        "normalizer = BaseNormalizer(\"hi\", remove_nuktas=False)\n",
        "# normalizer=factory.get_normalizer(\"hi\",remove_nuktas)\n",
        "output_text=normalizer.normalize(input_text)\n",
        "\n",
        "print(input_text)\n",
        "print()\n",
        "\n",
        "print('Before normalization')\n",
        "print(' '.join([ hex(ord(c)) for c in input_text ] ))\n",
        "print('Length: {}'.format(len(input_text)))\n",
        "print()\n",
        "print('After normalization')\n",
        "print(' '.join([ hex(ord(c)) for c in output_text ] ))\n",
        "print('Length: {}'.format(len(output_text)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "क़ क़\n",
            "\n",
            "Before normalization\n",
            "0x958 0x20 0x915 0x93c\n",
            "Length: 4\n",
            "\n",
            "After normalization\n",
            "0x958 0x20 0x915 0x93c\n",
            "Length: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ifKAp02g7R"
      },
      "source": [
        "## Sentence Splitter\n",
        "\n",
        "A smart sentence splitter which uses a two-pass rule-based system to split the text into sentences. It knows of common prefixes in Indian languages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwhP3bHT0pVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fff154e-950f-4a1b-b513-c34991f65f19"
      },
      "source": [
        "from indicnlp.tokenize import sentence_tokenize\n",
        "\n",
        "indic_string=\"\"\"तो क्या विश्व कप 2019 में मैच का बॉस टॉस है? यानी मैच में हार-जीत में \\\n",
        "टॉस की भूमिका अहम है? आप ऐसा सोच सकते हैं। विश्वकप के अपने-अपने पहले मैच में बुरी तरह हारने वाली एशिया की दो टीमों \\\n",
        "पाकिस्तान और श्रीलंका के कप्तान ने हालांकि अपने हार के पीछे टॉस की दलील तो नहीं दी, लेकिन यह जरूर कहा था कि वह एक अहम टॉस हार गए थे।\"\"\"\n",
        "sentences=sentence_tokenize.sentence_split(indic_string, lang='hi')\n",
        "for t in sentences:\n",
        "    print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "तो क्या विश्व कप 2019 में मैच का बॉस टॉस है?\n",
            "यानी मैच में हार-जीत में टॉस की भूमिका अहम है?\n",
            "आप ऐसा सोच सकते हैं।\n",
            "विश्वकप के अपने-अपने पहले मैच में बुरी तरह हारने वाली एशिया की दो टीमों पाकिस्तान और श्रीलंका के कप्तान ने हालांकि अपने हार के पीछे टॉस की दलील तो नहीं दी, लेकिन यह जरूर कहा था कि वह एक अहम टॉस हार गए थे।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY0XX-jZ21KE"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "A trivial tokenizer which just tokenizes on the punctuation boundaries. This also includes punctuations for the Indian language scripts (the purna virama and the deergha virama). It returns a list of tokens.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOTSj7U1KUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3cbea0-bdcd-4e04-9709-a038de735b14"
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "\n",
        "indic_string='सुनो, कुछ आवाज़ आ रही है। फोन?'\n",
        "\n",
        "print('Input String: {}'.format(indic_string))\n",
        "print('Tokens: ')\n",
        "for t in indic_tokenize.trivial_tokenize(indic_string):\n",
        "    print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input String: सुनो, कुछ आवाज़ आ रही है। फोन?\n",
            "Tokens: \n",
            "सुनो\n",
            ",\n",
            "कुछ\n",
            "आवाज़\n",
            "आ\n",
            "रही\n",
            "है\n",
            "।\n",
            "फोन\n",
            "?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdHOAg4L4hyR"
      },
      "source": [
        "## De-tokenization\n",
        "\n",
        "A de-tokenizer for Indian languages that can address punctuation in Indic languages. The de-tokenizer is useful when generating natural language output. It can be used as a post-processor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ejF9j7n1sv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9391b4-00c1-415c-da1c-644a1a3aeaca"
      },
      "source": [
        "from indicnlp.tokenize import indic_detokenize\n",
        "indic_string='\" सुनो , कुछ आवाज़ आ रही है . \" , उसने कहा । '\n",
        "\n",
        "print('Input String: {}'.format(indic_string))\n",
        "print('Detokenized String: {}'.format(indic_detokenize.trivial_detokenize(indic_string,lang='hi')))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input String: \" सुनो , कुछ आवाज़ आ रही है . \" , उसने कहा । \n",
            "Detokenized String: \"सुनो, कुछ आवाज़ आ रही है.\", उसने कहा। \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fphaAXmq4_ck"
      },
      "source": [
        "## Script Conversion\n",
        "\n",
        "Convert from one Indic script to another. This is a simple script which exploits the fact that Unicode points of various Indic scripts are at corresponding offsets from the base codepoint for that script. The following scripts are supported:\n",
        "\n",
        "_Devanagari (Hindi,Marathi,Sanskrit,Konkani,Sindhi,Nepali), Assamese, Bengali, Oriya, Gujarati, Gurumukhi (Punjabi), Sindhi, Tamil, Telugu, Kannada, Malayalam_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO3Bswlm4lXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a89dd6-71a4-4dc7-9c1d-8b988faadcc8"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
        "input_text='राजस्थान'\n",
        "# input_text='രാജസ്ഥാന'\n",
        "# input_text='රාජස්ථාන'\n",
        "print(UnicodeIndicTransliterator.transliterate(input_text,\"hi\",\"ta\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ராஜஸ்தாந\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN9DNvG66hXU"
      },
      "source": [
        "## Romanization\n",
        "\n",
        "Convert script text to Roman text in the ITRANS notation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4Rwha166ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2f8eda-51ca-426d-d14d-3edb92fa42ce"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "input_text='राजस्थान'\n",
        "# input_text='ஆசிரியர்கள்'\n",
        "lang='hi'\n",
        "\n",
        "print(ItransTransliterator.to_itrans(input_text,lang))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raajasthaana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvtPpSWv7I0P"
      },
      "source": [
        "## Indicization (ITRANS to Indic Script)\n",
        "\n",
        "Let's call conversion of ITRANS-transliteration to an Indic script as **Indicization**!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fonb19Tu6kPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3521004e-7a66-4b80-9676-08b95c8e3c88"
      },
      "source": [
        "from indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n",
        "\n",
        "input_text='kahaa jaanaa hai?'\n",
        "lang='hi'\n",
        "x=ItransTransliterator.from_itrans(input_text,lang)\n",
        "print(x)\n",
        "for y in x:\n",
        "    print('{:x}'.format(ord(y)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "कहा जाना है?\n",
            "915\n",
            "939\n",
            "93e\n",
            "20\n",
            "91c\n",
            "93e\n",
            "928\n",
            "93e\n",
            "20\n",
            "939\n",
            "948\n",
            "3f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV7p0qM88Bdf"
      },
      "source": [
        "## Script Information\n",
        "\n",
        "Indic scripts have been designed keeping phonetic principles in nature and the design and organization of the scripts makes it easy to obtain phonetic information about the characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUOnZkH28FnW"
      },
      "source": [
        "### Get Phonetic Feature Vector\n",
        "\n",
        "With each script character, a phontic feature vector is associated, which encodes the phontic properties of the character. This is a bit vector which is can be obtained as shown below:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-QPFp507LIs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04dbfb77-769f-4475-ba30-93553d859c97"
      },
      "source": [
        "from indicnlp.script import  indic_scripts as isc\n",
        "\n",
        "c='क'\n",
        "lang='hi'\n",
        "\n",
        "isc.get_phonetic_feature_vector(c,lang)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r4rpCa48O64"
      },
      "source": [
        "This fields in this bit vector are (from left to right):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpqv4Iu88LMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbdd24a5-1518-46d7-ede1-a75f46106575"
      },
      "source": [
        "sorted(isc.PV_PROP_RANGES.items(),key=lambda x:x[1][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('basic_type', [0, 6]),\n",
              " ('vowel_length', [6, 8]),\n",
              " ('vowel_strength', [8, 11]),\n",
              " ('vowel_status', [11, 13]),\n",
              " ('consonant_type', [13, 18]),\n",
              " ('articulation_place', [18, 23]),\n",
              " ('aspiration', [23, 25]),\n",
              " ('voicing', [25, 27]),\n",
              " ('nasalization', [27, 29]),\n",
              " ('vowel_horizontal', [29, 32]),\n",
              " ('vowel_vertical', [32, 36]),\n",
              " ('vowel_roundness', [36, 38])]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G58e__8a8ZmQ"
      },
      "source": [
        "You can check the phonetic information database files in Indic NLP resources to know the definition of each of the bits.\n",
        "\n",
        "- _For Tamil Script_: [database](https://github.com/anoopkunchukuttan/indic_nlp_resources/blob/master/script/tamil_script_phonetic_data.csv)\n",
        "- _For other Indic Scripts_: [database](https://github.com/anoopkunchukuttan/indic_nlp_resources/blob/master/script/all_script_phonetic_data.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR3OJQbk8h5h"
      },
      "source": [
        "### Query Phonetic Properties\n",
        "\n",
        "**Note:** _This interface below will be deprecated soon and a new interface will be available soon._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ka6GUk08R68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e465fb8-6b7e-4d68-82c3-f8dc5c26f36b"
      },
      "source": [
        "from indicnlp.langinfo import *\n",
        "\n",
        "c='क'\n",
        "lang='hi'\n",
        "\n",
        "print('Is vowel?:  {}'.format(is_vowel(c,lang)))\n",
        "print('Is consonant?:  {}'.format(is_consonant(c,lang)))\n",
        "print('Is velar?:  {}'.format(is_velar(c,lang)))\n",
        "print('Is palatal?:  {}'.format(is_palatal(c,lang)))\n",
        "print('Is aspirated?:  {}'.format(is_aspirated(c,lang)))\n",
        "print('Is unvoiced?:  {}'.format(is_unvoiced(c,lang)))\n",
        "print('Is nasal?:  {}'.format(is_nasal(c,lang)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is vowel?:  False\n",
            "Is consonant?:  True\n",
            "Is velar?:  True\n",
            "Is palatal?:  False\n",
            "Is aspirated?:  False\n",
            "Is unvoiced?:  True\n",
            "Is nasal?:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix-66lmj8wXn"
      },
      "source": [
        "### Get Phonetic Similarity\n",
        "\n",
        "Using the phonetic feature vectors, we can define phonetic similarity between the characters (and underlying phonemes). The library implements some  measures for phonetic similarity between the characters (and underlying phonemes). These can be defined using the phonetic feature vectors discussed earlier, so users can implement additional similarity measures.\n",
        "\n",
        "The implemented similarity measures are:\n",
        "\n",
        "- cosine\n",
        "- dice\n",
        "- jaccard\n",
        "- dot_product\n",
        "- sim1 (Kunchukuttan _et al._, 2016)\n",
        "- softmax\n",
        "\n",
        "** References **\n",
        "\n",
        "Anoop Kunchukuttan, Pushpak Bhattacharyya, Mitesh Khapra. _Substring-based unsupervised transliteration with phonetic and contextual knowledge_. SIGNLL Conference on Computational Natural Language Learning ** (CoNLL 2016) **. 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46MXrfhn8lj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573d9193-a27f-438c-c0dc-badc2b1f7b2b"
      },
      "source": [
        "from indicnlp.script import  indic_scripts as isc\n",
        "from indicnlp.script import  phonetic_sim as psim\n",
        "\n",
        "c1='क'\n",
        "c2='ख'\n",
        "c3='भ'\n",
        "lang='hi'\n",
        "\n",
        "print('Similarity between {} and {}'.format(c1,c2))\n",
        "print(psim.cosine(\n",
        "    isc.get_phonetic_feature_vector(c1,lang),\n",
        "    isc.get_phonetic_feature_vector(c2,lang)\n",
        "    ))\n",
        "\n",
        "print()\n",
        "\n",
        "print(u'Similarity between {} and {}'.format(c1,c3))\n",
        "print(psim.cosine(\n",
        "    isc.get_phonetic_feature_vector(c1,lang),\n",
        "    isc.get_phonetic_feature_vector(c3,lang)\n",
        "    ))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between क and ख\n",
            "0.8333319444467593\n",
            "\n",
            "Similarity between क and भ\n",
            "0.4999991666680556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2u_EPpq9LBZ"
      },
      "source": [
        "_You may have figured out that you can also compute similarities of characters belonging to different scripts._\n",
        "\n",
        "You can also get a similarity matrix which contains the similarities between all pairs of characters (within the same script or across scripts).\n",
        "\n",
        "Let's see how we can compare the characters across Devanagari and Malayalam scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrjZF5Ac8-hv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78523ce-3039-447d-cb95-07bb58d701f3"
      },
      "source": [
        "from indicnlp.script import  indic_scripts as isc\n",
        "from indicnlp.script import  phonetic_sim as psim\n",
        "\n",
        "\n",
        "slang='hi'\n",
        "tlang='ml'\n",
        "sim_mat=psim.create_similarity_matrix(psim.cosine,slang,tlang,normalize=False)\n",
        "\n",
        "c1='क'\n",
        "c2='ഖ'\n",
        "print('Similarity between {} and {}'.format(c1,c2))\n",
        "print(sim_mat[isc.get_offset(c1,slang),isc.get_offset(c2,tlang)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between क and ഖ\n",
            "0.8333319444467593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhVmMFPU9Q36"
      },
      "source": [
        "Some similarity functions like `sim` do not generate values in the range [0,1] and it may be more convenient to have the similarity values in the range [0,1]. This can be achieved by setting the `normalize` paramter to `True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3okYMsR9N2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc4580c-65b8-45ef-c1ab-9f8a813c0f0c"
      },
      "source": [
        "slang='hi'\n",
        "tlang='ml'\n",
        "sim_mat=psim.create_similarity_matrix(psim.sim1,slang,tlang,normalize=True)\n",
        "\n",
        "c1='क'\n",
        "c2='ഖ'\n",
        "print(u'Similarity between {} and {}'.format(c1,c2))\n",
        "print(sim_mat[isc.get_offset(c1,slang),isc.get_offset(c2,tlang)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between क and ഖ\n",
            "0.06860894001932027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFLwvmoe9Yr5"
      },
      "source": [
        "### Lexical Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKLSRVHb9T-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e25d2b7-930a-4142-c231-dff48a84c8ac"
      },
      "source": [
        "from indicnlp.script import  indic_scripts as isc\n",
        "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
        "\n",
        "lang1_str='पिछले दिनों हम लोगों ने कई उत्सव मनाये. कल, हिन्दुस्तान भर में श्री कृष्ण जन्म-महोत्सव मनाया गया.'\n",
        "lang2_str='વીતેલા દિવસોમાં આપણે કેટલાય ઉત્સવો ઉજવ્યા. હજી ગઇકાલે જ પૂરા હિંદુસ્તાનમાં શ્રીકૃષ્ણ જન્મોત્સવ ઉજવવામાં આવ્યો.'\n",
        "lang1='hi'\n",
        "lang2='gu'\n",
        "\n",
        "lcsr, len1, len2 = isc.lcsr_indic(lang1_str,lang2_str,lang1,lang2)\n",
        "\n",
        "print('{} string: {}'.format(lang1, lang1_str))\n",
        "print('{} string: {}'.format(lang2, UnicodeIndicTransliterator.transliterate(lang2_str,lang2,lang1)))\n",
        "print('Both strings are shown in Devanagari script using script conversion for readability.')\n",
        "print('LCSR: {}'.format(lcsr))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi string: पिछले दिनों हम लोगों ने कई उत्सव मनाये. कल, हिन्दुस्तान भर में श्री कृष्ण जन्म-महोत्सव मनाया गया.\n",
            "gu string: वीतेला दिवसोमां आपणे केटलाय उत्सवो उजव्या. हजी गइकाले ज पूरा हिंदुस्तानमां श्रीकृष्ण जन्मोत्सव उजववामां आव्यो.\n",
            "Both strings are shown in Devanagari script using script conversion for readability.\n",
            "LCSR: 0.5545454545454546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnSk-3L79wOF"
      },
      "source": [
        "## Orthographic Syllabification\n",
        "\n",
        "_Orthographic Syllabification_ is an approximate syllabification process for Indic scripts, where CV+ units are defined to be _orthographic syllables_.\n",
        "\n",
        "See the following paper for details:\n",
        "\n",
        "Anoop Kunchukuttan, Pushpak Bhattacharyya. [_Orthographic Syllable as basic unit for SMT between Related Languages_](https://arxiv.org/abs/1610.00634). Conference on Empirical Methods in Natural Language Processing **(EMNLP 2016)**. 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keRZ7sOV9bZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "141eb013-a951-48ba-a930-7c8b46128767"
      },
      "source": [
        "from indicnlp.syllable import  syllabifier\n",
        "\n",
        "w='जगदीशचंद्र'\n",
        "lang='hi'\n",
        "\n",
        "print(' '.join(syllabifier.orthographic_syllabify(w,lang)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ज ग दी श च ंद्र\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HcBon6d922Z"
      },
      "source": [
        "## Word Segmentation\n",
        "\n",
        "Unsupervised morphological analysers for various Indian language. Given a word, the analyzer returns the componenent morphemes.\n",
        "The analyzer can recognize inflectional and derivational morphemes.\n",
        "\n",
        "The following languages are supported:\n",
        "\n",
        "_Hindi, Punjabi, Marathi, Konkani, Gujarati, Bengali, Kannada, Tamil, Telugu, Malayalam_\n",
        "\n",
        "Support for more languages will be added soon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e6yeJNL9zkb"
      },
      "source": [
        "from indicnlp.morph import unsupervised_morph\n",
        "from indicnlp import common\n",
        "\n",
        "analyzer=unsupervised_morph.UnsupervisedMorphAnalyzer('mr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDCUiRmT97x3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c2a7dd-532b-4862-efac-70625ce5d460"
      },
      "source": [
        "indic_string='आपल्या हिरड्यांच्या आणि दातांच्यामध्ये जीवाणू असतात .'\n",
        "\n",
        "analyzes_tokens=analyzer.morph_analyze_document(indic_string.split(' '))\n",
        "\n",
        "for w in analyzes_tokens:\n",
        "    print(w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "आपल्या\n",
            "हिरड्या\n",
            "ंच्या\n",
            "आणि\n",
            "दाता\n",
            "ंच्या\n",
            "मध्ये\n",
            "जीवाणू\n",
            "असतात\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIvuMfJN-i4q"
      },
      "source": [
        "### Acronyms\n",
        "\n",
        "Acronyms have a different behaviour while transliterating. Hence, a rule-based transliterator for transliterating English acronyms to Indian languages is available.\n",
        "\n",
        "This can also be used to generate synthetic transliteration data to train a Indian language to English transliterator for acronyms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWnyUUDS-bQ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ec93afe-2616-4864-f826-13202feaba21"
      },
      "source": [
        "from indicnlp.transliterate import acronym_transliterator\n",
        "\n",
        "ack_transliterator=acronym_transliterator.LatinToIndicAcronymTransliterator()\n",
        "ack_transliterator.transliterate('ICICI',lang='hi')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'आईसीआईसीआई'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhCIc6ZdANNu"
      },
      "source": [
        "# Regular Expresion(RE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AfRDvUlW2-O"
      },
      "source": [
        "A regular expression is a special sequence of characters that helps you match or find other strings or sets of strings, using a specialized syntax held in a pattern.\n",
        "Tutorials Taken from [py4e](https://www.py4e.com/html3/11-regex), [w3schools](https://www.w3schools.com/python/python_regex.asp) and [w3resource](https://www.w3resource.com/python-exercises/re/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAOnQAWZAvJx"
      },
      "source": [
        "The regular expression library re must be imported into your program before you can use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKxfhHFAAPn_"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsjvkf1iFw1u"
      },
      "source": [
        "**Here are some of those special characters and character sequences:**\n",
        "\n",
        "`^` Matches the beginning of the line.\n",
        "\n",
        "`$` Matches the end of the line.\n",
        "\n",
        "`.` Matches any character (a wildcard).\n",
        "\n",
        "`\\s` Matches a whitespace character.\n",
        "\n",
        "`\\S` Matches a non-whitespace character (opposite of \\s).\n",
        "\n",
        "`*` Applies to the immediately preceding character(s) and indicates to match zero or more times.\n",
        "\n",
        "`*?` Applies to the immediately preceding character(s) and indicates to match zero or more times in “non-greedy mode”.\n",
        "\n",
        "`+` Applies to the immediately preceding character(s) and indicates to match one or more times.\n",
        "\n",
        "`|`\tEither or\n",
        "\n",
        "`+?` Applies to the immediately preceding character(s) and indicates to match one or more times in “non-greedy mode”.\n",
        "\n",
        "`?` Applies to the immediately preceding character(s) and indicates to match zero or one time.\n",
        "\n",
        "`??` Applies to the immediately preceding character(s) and indicates to match zero or one time in “non-greedy mode”.\n",
        "\n",
        "`[aeiou]` Matches a single character as long as that character is in the specified set. In this example, it would match “a”, “e”, “i”, “o”, or “u”, but no other characters.\n",
        "\n",
        "`[a-z0-9]` You can specify ranges of characters using the minus sign. This example is a single character that must be a lowercase letter or a digit.\n",
        "\n",
        "`[^A-Za-z]` When the first character in the set notation is a caret, it inverts the logic. This example matches a single character that is anything other than an uppercase or lowercase letter.\n",
        "\n",
        "`( )` When parentheses are added to a regular expression, they are ignored for the purpose of matching, but allow you to extract a particular subset of the matched string rather than the whole string when using findall().\n",
        "\n",
        "`\\b` Matches the empty string, but only at the start or end of a word.\n",
        "\n",
        "`\\B` Matches the empty string, but not at the start or end of a word.\n",
        "\n",
        "`\\d` Matches any decimal digit; equivalent to the set [0-9].\n",
        "\n",
        "`\\D` Matches any non-digit character; equivalent to the set [^0-9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYfx-5n6NNYM"
      },
      "source": [
        "## RegEx Functions\n",
        "The `re` module offers a set of functions that allows us to search a string for a match:\n",
        "\n",
        "Function  | Description\n",
        "------------- | -------------\n",
        "findall  | Returns a list containing all matches\n",
        "search  | Returns a Match object if there is a match anywhere in the string\n",
        "split  | Returns a list where the string has been split at each match\n",
        "sub  | Replaces one or many matches with a string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz3clSfYPFfC"
      },
      "source": [
        "### The findall() Function\n",
        "The `findall()` function returns a list containing all matches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAODxRYxPTZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d2950db-98bd-4005-951c-ca7261526d1f"
      },
      "source": [
        "txt = \"The rain in Spain\"\n",
        "x = re.findall(\"ai\", txt)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai', 'ai']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4La5KZO_PYe0"
      },
      "source": [
        "The list contains the matches in the order they are found.\n",
        "\n",
        "If no matches are found, an empty list is returned:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QFfaEZaPd7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d97a7298-9c72-477b-8fae-d639428a9e84"
      },
      "source": [
        "# Return an empty list if no match was found:\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.findall(\"Portugal\", txt)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGdGHqXJPt2b"
      },
      "source": [
        "### The search() Function\n",
        "The `search()` function searches the string for a match, and returns a Match object if there is a match.\n",
        "\n",
        "If there is more than one match, only the first occurrence of the match will be returned:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBRLJgUGP4aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "768e55e8-66e0-4f05-d1fe-85ff8796d178"
      },
      "source": [
        "#Search for the first white-space character in the string:\n",
        "\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.search(\"\\s\", txt)\n",
        "\n",
        "print(\"The first white-space character is located in position:\", x.start())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first white-space character is located in position: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYX7-QcIP_9K"
      },
      "source": [
        "If no matches are found, the value `None` is returned:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6KEj0aLQHKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2f5c8d-b2f7-4fd2-9d86-0179368ff769"
      },
      "source": [
        "# Make a search that returns no match:\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.search(\"Portugal\", txt)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXUhoJQaQP0-"
      },
      "source": [
        "### The split() function\n",
        "The `split()` function returns a list where the string has been split at each match:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpWuJA49QqO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938c3508-f3bd-4b86-9a5c-8d3cbad47e76"
      },
      "source": [
        "# Split at each white-space character:\n",
        "\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.split(\"\\s\", txt)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'rain', 'in', 'Spain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-f-HzkKQ3Cz"
      },
      "source": [
        "You can control the number of occurrences by specifying the maxsplit parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhiwpXTvQ2h4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ba2983-62dd-4ef4-b249-b7d80089fe4a"
      },
      "source": [
        "txt = \"The rain in Spain\"\n",
        "x = re.split(\"\\s\", txt, 1)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'rain in Spain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE0TpWegQ_CM"
      },
      "source": [
        "### The sub() Function\n",
        "The `sub()` function replaces the matches with the text of your choice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9jZDW7sRFnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb235a67-4965-45ea-fa71-425c0f388b29"
      },
      "source": [
        "# Replace every white-space character with the number 9:\n",
        "\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.sub(\"\\s\", \"9\", txt)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The9rain9in9Spain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGFBEXhqRRs6"
      },
      "source": [
        "You can control the number of replacements by specifying the count parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_HzpBV-RzHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3759845b-3b66-4f2d-e5a0-d11bb8061a05"
      },
      "source": [
        "#Replace the first 2 occurrences:\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.sub(\"\\s\", \"9\", txt, 2)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The9rain9in Spain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_FeWSZsSGfG"
      },
      "source": [
        "### Match Object\n",
        "A Match Object is an object containing information about the search and the result.\n",
        "\n",
        "Note: If there is no match, the value `None` will be returned, instead of the Match Object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EHbjjRLSS9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c7255d-1274-4286-ca57-b36905578159"
      },
      "source": [
        "# Do a search that will return a Match Object:\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.search(\"ai\", txt)\n",
        "print(x) #this will print an object"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<re.Match object; span=(5, 7), match='ai'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl5c35LrScbJ"
      },
      "source": [
        "The Match object has properties and methods used to retrieve information about the search, and the result:\n",
        "\n",
        "`.span()` returns a tuple containing the start-, and end positions of the match.\n",
        "\n",
        "`.string` returns the string passed into the function\n",
        "\n",
        "`.group()` returns the part of the string where there was a match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvyRtIa7Sm7y"
      },
      "source": [
        "**Example of span() Function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7FmNtMOSn8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc405a9-56ff-47b4-8984-d4d290449946"
      },
      "source": [
        "# Print the position (start- and end-position) of the first match occurrence.\n",
        "\n",
        "# The regular expression looks for any words that starts with an upper case \"S\":\n",
        "\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.search(r\"\\bS\\w+\", txt)\n",
        "print(x.span())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQpsi5b8TM8l"
      },
      "source": [
        "**Example of string() Function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfEUJq5qS8YX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a5622a2-15c6-48bc-b880-16924542119c"
      },
      "source": [
        "# Print the string passed into the function:\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.search(r\"\\bS\\w+\", txt)\n",
        "print(x.string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rain in Spain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEeUm1v7TPld"
      },
      "source": [
        "**Example of group() Function:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtQ76641TSnb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2ceb94-6336-408e-8d88-d8bcaeca0ca0"
      },
      "source": [
        "# Print the part of the string where there was a match.\n",
        "\n",
        "# The regular expression looks for any words that starts with an upper case \"S\":\n",
        "\n",
        "txt = \"The rain in Spain\"\n",
        "x = re.search(r\"\\bS\\w+\", txt)\n",
        "print(x.group())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrJ_qxRrBBNs"
      },
      "source": [
        "### Remove all whitespaces from a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ju5mg6DAyO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ec9e6b-057d-4259-9a13-46bd07dbf478"
      },
      "source": [
        "text1 = ' Regular   Expresion '\n",
        "print(\"Original string:\",text1)\n",
        "print(\"Without extra spaces:\",re.sub(r'\\s+', '',text1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string:  Regular   Expresion \n",
            "Without extra spaces: RegularExpresion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_c8XHUPCNVR"
      },
      "source": [
        "# TODO: Remove all whitespaces from a string.\n",
        "\n",
        "text2 = '       Regular   Expresion '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uF-hYZN-EHa2"
      },
      "source": [
        "### Remove multiple spaces in a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FCNeqg_CRa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03205035-cf21-48f2-852b-2d260e0e9d77"
      },
      "source": [
        "text1 = '        Regular   Expresion '\n",
        "print(\"Original string:\",text1)\n",
        "print(\"Without extra spaces:\",re.sub(' +',' ',text1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string:         Regular   Expresion \n",
            "Without extra spaces:  Regular Expresion \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_fsPP99MVoZ"
      },
      "source": [
        "## Extracting data using regular expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QUL_dY1Er_z"
      },
      "source": [
        "### Extract values between quotation marks of a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTF28KYtEXf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc13acd-4218-48c1-e0d8-e821d71bc5c0"
      },
      "source": [
        "text1 = '\"Natural\", \"Language\", \"Processing\"'\n",
        "print(re.findall(r'\"(.*?)\"', text1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Kk--CnLao4"
      },
      "source": [
        "### Escape character\n",
        "\n",
        "Since we use special characters in regular expressions to match the beginning or end of a line or specify wild cards, we need a way to indicate that these characters are “normal” and we want to match the actual character such as a dollar sign or caret.\n",
        "\n",
        "We can indicate that we want to simply match a character by prefixing that character with a backslash. For example, we can find money amounts with the following regular expression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQWCqM_2LsSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a3bca3-ab6c-4445-ef11-5ceb4b3bf687"
      },
      "source": [
        "x = 'We just received $10.00 for cookies.'\n",
        "y = re.findall('\\$[0-9.]+',x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['$10.00']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj-CQsdHLuMF"
      },
      "source": [
        "Since we prefix the dollar sign with a backslash, it actually matches the dollar sign in the input string instead of matching the “end of line”, and the rest of the regular expression matches one or more digits or the period character.\n",
        "\n",
        "Note: Inside square brackets, characters are not “special”. So when we say [0-9.], it really means digits or a period. Outside of square brackets, a period is the “wild-card” character and matches any character. Inside square brackets, the period is a period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LL5woukHBnR"
      },
      "source": [
        "### Extract domain ('gmail.com') from the Email Address."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CERC1ttSEwVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61546dbc-8d26-4eaa-db26-8c3df868199a"
      },
      "source": [
        "sentence = \"From nlp.course.iitk@gmail.com Sat September  5 09:14:16 2020\"\n",
        "domain = re.findall(\"@(\\S+)\", sentence)\n",
        "print(domain)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gmail.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPLf9laJHUZn"
      },
      "source": [
        "### Extract the Email address"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIymt_SNHOao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92089d5b-050e-486a-e3a8-93e68786df97"
      },
      "source": [
        "sentence = \"From nlp.course.iitk@gmail.com Sat September  5 09:14:16 2020\"\n",
        "y = re.findall(\"\\S+?@\\S+\", sentence)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nlp.course.iitk@gmail.com']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IR8E0jVHhJZ"
      },
      "source": [
        "### Remove leading zeros from an IP address"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz1JuRpfHYTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9002f40-7b2e-413d-a49d-6201157e72e9"
      },
      "source": [
        "ip = \"216.08.094.196\"\n",
        "string = re.sub('\\.[0]*', '.', ip)\n",
        "print(string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "216.8.94.196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZskNFeTHx9G"
      },
      "source": [
        "### Remove lowercase substrings from a given string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpIKfw_fHlg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e72342ca-0024-4829-a81a-6ba055e8b4d7"
      },
      "source": [
        "str1 = 'CS698V/CS779: Statistical NATURAL LANGUAGE PROCESSING (NLP). Parsing: CFG, Lexicalized CFG, PCFGs, Dependency parsing'\n",
        "print(\"Original string:\")\n",
        "print(str1)\n",
        "print(\"After removing lowercase letters, above string becomes:\")\n",
        "remove_lower = lambda text: re.sub('[a-z]', '', text)\n",
        "result =  remove_lower(str1)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string:\n",
            "CS698V/CS779: Statistical NATURAL LANGUAGE PROCESSING (NLP). Parsing: CFG, Lexicalized CFG, PCFGs, Dependency parsing\n",
            "After removing lowercase letters, above string becomes:\n",
            "CS698V/CS779: S NATURAL LANGUAGE PROCESSING (NLP). P: CFG, L CFG, PCFG, D \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97Yqd2wVH5Ta"
      },
      "source": [
        "### Insert spaces between words starting with capital letters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCNkShaFH2AY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b52bb7d-4e15-41b1-84e2-7241bc10b9b2"
      },
      "source": [
        "str1 = \"NaturalLanguageProcessing\"\n",
        "string = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", str1)\n",
        "print(string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAlidjOqIBW2"
      },
      "source": [
        "### Remove the parenthesis area in a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crq77mEEH9jY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43a450c-aa21-4b1c-de3c-c8a7363cedd9"
      },
      "source": [
        "items = [\"Natural Language Processing (NLP)\", \"IITK\", \"gmail (.com)\", \"CS (779)\"]\n",
        "\n",
        "for item in items:\n",
        "    print(re.sub(r\" ?\\([^)]+\\)\", \"\", item))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing\n",
            "IITK\n",
            "gmail\n",
            "CS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFko9i7lIIfH"
      },
      "source": [
        "### Remove the ANSI escape sequences from a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyXQyY7qIE5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d0f195-dbb7-4e0f-c787-f5aa2ac31bd0"
      },
      "source": [
        "text = \"\\t\\u001b[0;35mCS779\\u001b[0m \\u001b[0;36mStatistical Natural Language Processing\\u001b[0m\"\n",
        "print(\"Original Text: \",text)\n",
        "reaesc = re.compile(r'\\x1b[^m]*m')\n",
        "new_text = reaesc.sub('', text)\n",
        "print(\"New Text: \",new_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:  \t\u001b[0;35mCS779\u001b[0m \u001b[0;36mStatistical Natural Language Processing\u001b[0m\n",
            "New Text:  \tCS779 Statistical Natural Language Processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM8y_SVqIzQM"
      },
      "source": [
        "## Download a sample text file which records mail activity from various individuals in an open source project development team."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPxe6P5CIMn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c15467-f2d7-4853-8c92-0dce990c17cc"
      },
      "source": [
        "!wget \"http://www.py4inf.com/code/mbox-short.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-03 18:28:47--  http://www.py4inf.com/code/mbox-short.txt\n",
            "Resolving www.py4inf.com (www.py4inf.com)... 74.208.236.248, 2607:f1c0:100f:f000::2df\n",
            "Connecting to www.py4inf.com (www.py4inf.com)|74.208.236.248|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.dr-chuck.com/py4inf/code/mbox-short.txt [following]\n",
            "--2025-02-03 18:28:47--  https://www.dr-chuck.com/py4inf/code/mbox-short.txt\n",
            "Resolving www.dr-chuck.com (www.dr-chuck.com)... 74.208.236.248, 2607:f1c0:100f:f000::2df\n",
            "Connecting to www.dr-chuck.com (www.dr-chuck.com)|74.208.236.248|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94626 (92K) [text/plain]\n",
            "Saving to: ‘mbox-short.txt’\n",
            "\n",
            "mbox-short.txt      100%[===================>]  92.41K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2025-02-03 18:28:48 (1.72 MB/s) - ‘mbox-short.txt’ saved [94626/94626]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94ZZ-vt0JqlP"
      },
      "source": [
        "hand = open('/content/mbox-short.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHmLRKO2KNAd"
      },
      "source": [
        "### Search for lines that start with From and have an at sign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni3GzC0TJ7lN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a349a78f-3ed1-4c21-dfda-ee420ef4a52f"
      },
      "source": [
        "for line in hand:\n",
        "    line = line.rstrip()\n",
        "    if re.search('^From:.+@', line):\n",
        "        print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: stephen.marquard@uct.ac.za\n",
            "From: louis@media.berkeley.edu\n",
            "From: zqian@umich.edu\n",
            "From: rjlowe@iupui.edu\n",
            "From: zqian@umich.edu\n",
            "From: rjlowe@iupui.edu\n",
            "From: cwen@iupui.edu\n",
            "From: cwen@iupui.edu\n",
            "From: gsilver@umich.edu\n",
            "From: gsilver@umich.edu\n",
            "From: zqian@umich.edu\n",
            "From: gsilver@umich.edu\n",
            "From: wagnermr@iupui.edu\n",
            "From: zqian@umich.edu\n",
            "From: antranig@caret.cam.ac.uk\n",
            "From: gopal.ramasammycook@gmail.com\n",
            "From: david.horwitz@uct.ac.za\n",
            "From: david.horwitz@uct.ac.za\n",
            "From: david.horwitz@uct.ac.za\n",
            "From: david.horwitz@uct.ac.za\n",
            "From: stephen.marquard@uct.ac.za\n",
            "From: louis@media.berkeley.edu\n",
            "From: louis@media.berkeley.edu\n",
            "From: ray@media.berkeley.edu\n",
            "From: cwen@iupui.edu\n",
            "From: cwen@iupui.edu\n",
            "From: cwen@iupui.edu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTeg-W0IJ_DE"
      },
      "source": [
        "# TODO:\n",
        "# Search for lines that start with 'X' followed by any non\n",
        "# whitespace characters and ':'\n",
        "# followed by a space and any number.\n",
        "# The number can include a decimal."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAyJORhWKgrL"
      },
      "source": [
        "# TODO:\n",
        "# Search for lines that start with 'X' followed by any\n",
        "# non whitespace characters and ':' followed by a space\n",
        "# and any number. The number can include a decimal.\n",
        "# Then print the number if it is greater than zero."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NArjLQV9KjtM"
      },
      "source": [
        "# TODO:\n",
        "# Search for lines that start with 'Details: rev='\n",
        "# followed by numbers and '.'\n",
        "# Then print the number if it is greater than zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqeCkQ-PKmbe"
      },
      "source": [
        "# TODO:\n",
        "# Search for lines that start with From and a character\n",
        "# followed by a two digit number between 00 and 99 followed by ':'\n",
        "# Then print the number if it is greater than zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_bHU1JJLEtq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}